# DVC
git init
dvc init  ( we use dvc+supporting SCM tool always here)


<!-- add dvc :: letting dvc to manage data_folder-->
dvc add path/data_folder/


dvc config core.analytics false

<!-- autotage -->
dvc config core.autostage true

<!-- space check -->
dvc du path/data_folder/

<!-- check dvc remote -->
dvc remote list


<!-- GOOGLE DRive -->
```sh
$ Google API Console
>> Enable Drive API
>> create credentials >> user-data >> APP-NAme, Developer-contact, Test-User SAVE
>> **CLIENT-ID** and **CLIENT-SECRET**
>> **API KEY**
```

<!-- add gdrive -->
dvc remote add --default remote-name gdrive:/GDRIVE-ID
dvc remote modify gdrive gdrive_acknowledge_abuse true

dvc remote modify gdrive gdrive_clien_id CLIENT-ID
dvc remote modify gdrive gdrive_clien_secret  CLIENT-SECRET

<!-- push to dgrive and manage -->
dvc push -r gdrive

<!-- whenever data change and commit dvc md5 hash changes, do  git commit `best practise` -->
<!-- git push won't allow because of the secrets, click the link and allow it -->
[reference 1](https://medium.com/@ajithkumarv/setting-up-a-workflow-with-dvc-google-drive-and-github-actions-f3775de4bf63)
[reference 2](https://medium.com/@ajithkumarv/setting-up-a-workflow-with-dvc-google-cloud-storage-gcs-bucket-and-github-actions-95cfa71e4386)


<-- pull it from dvc -->
dvc pull -r local

<-- checkout -->
git checkout ...
dvc checkout


<!-- Data Pipelines:: dvc stage -->
dvc stage 
    -n `name of the stage to add`  '--name name'
    -p `Declare parameter to use as additional dependency`  '-params [<filename>:]<params_list>'
    -d `Declare dependencies for reproducible cmd`  '--deps <path>'
    -o `Declare output file or directory`  '--outs <filename>'
    src/python.py


```sh
dvc stage add 
    -n train 
    -d src/train.py 
    -d configs/experiment/catdog.yaml 
    -o logs 
    -o outputs 
python src/train.py data.batch_size=64 model.pretrained=false trainer.max_epochs=10 logger=comet
```
edit:: `data.dvc`

<!-- reproduce -->
dvc repro
